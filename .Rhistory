})
test_that("initial_data function raises error if input data file does
not exist", {
# Call the function with a non-existent file path
expect_error(
initial_data("./tests/testthat/helpers/data/nonexistent_file.csv",
col_names))
})
test_that("initial_data function raises error if input is not a CSV file", {
# Create a non-CSV file
file.create("./tests/testthat/helpers/data/noncsv_file.txt")
# Call the function with the non-CSV file
expect_error(initial_data("./data/noncsv_file.txt", col_names))
# Delete the non-CSV file
file.remove("./tests/testthat/helpers/data/noncsv_file.txt")
})
test_that("initial_data function raises error if input data file is empty", {
# Create an empty CSV file
write.csv(data.frame(), "./tests/testthat/helpers/data/empty_file.csv")
# Call the function with the empty CSV file
expect_error(initial_data("./tests/testthat/helpers/data/empty_file.csv",
col_names))
# Delete the empty CSV file
file.remove("./tests/testthat/helpers/data/empty_file.csv")
})
test_that("initial_data function raises error if number of column names does
not match number of columns in input data", {
# Create a column names vector with a different length than the number of
# columns in the input data
col_names_wrong <- c("col1", "col2")
# Call the function with the mismatched column names vector
expect_error(initial_data("./tests/testthat/helpers/data/data_set.csv",
col_names_wrong))
})
check()
check()
# Test cases
test_that("initial_data function reads data and sets column names correctly", {
# Call the function
actual_data <- initial_data("./tests/testthat/helpers/data/data_set.csv",
col_names)
# Test that the data has the expected number of observations
expect_equal(nrow(actual_data), nrow(expected_data))
# Test that the data has the expected column names
expect_equal(colnames(actual_data), colnames(expected_data))
# Test that the function returns a data frame
expect_type(actual_data, "list")
})
styler:::style_active_file()
# Load expected input and output data, and initial_data script from R folder
# Test cases
test_that("initial_data function reads data and sets column names correctly", {
# Set helpers and call the function
data_set <- data.frame(
x = c(1, 2, 3),
y = c(4, 5, 6),
z = c(7, 8, 9)
)
write.csv(data_set, "./tests/testthat/helpers/data/data_set.csv",
row.names = FALSE
)
# Defining column names
col_names <- c("col1", "col2", "col3")
# Defining expected data
expected_data <- data.frame(
col1 = c(1, 2, 3),
col2 = c(4, 5, 6),
col3 = c(7, 8, 9)
)
actual_data <- initial_data(
"./tests/testthat/helpers/data/data_set.csv",
col_names
)
# Test that the data has the expected number of observations
expect_equal(nrow(actual_data), nrow(expected_data))
# Test that the data has the expected column names
expect_equal(colnames(actual_data), colnames(expected_data))
# Test that the function returns a data frame
expect_type(actual_data, "list")
# Delete the helper file
file.remove("./tests/testthat/helpers/data/data_set.csv")
})
test_that("initial_data function raises error if input data file does
not exist", {
# Call the function with a non-existent file path
expect_error(
initial_data(
"./tests/testthat/helpers/data/nonexistent_file.csv",
col_names
)
)
})
test_that("initial_data function raises error if input is not a CSV file", {
# Create a non-CSV file
file.create("./tests/testthat/helpers/data/noncsv_file.txt")
# Call the function with the non-CSV file
expect_error(initial_data(
"./tests/testthat/helpers/data/noncsv_file.txt",
col_names
))
# Delete the non-CSV file
file.remove("./tests/testthat/helpers/data/noncsv_file.txt")
})
test_that("initial_data function raises error if input data file is empty", {
# Create an empty CSV file
write.csv(data.frame(), "./tests/testthat/helpers/data/empty_file.csv")
# Call the function with the empty CSV file
expect_error(initial_data(
"./tests/testthat/helpers/data/empty_file.csv",
col_names
))
# Delete the empty CSV file
file.remove("./tests/testthat/helpers/data/empty_file.csv")
})
test_that("initial_data function raises error if number of column names does
not match number of columns in input data", {
# Set up helper data
data_set <- data.frame(
x = c(1, 2, 3),
y = c(4, 5, 6),
z = c(7, 8, 9)
)
write.csv(data_set, "./tests/testthat/helpers/data/data_set.csv",
row.names = FALSE
)
# Create a column names vector with a different length than the number of
# columns in the input data
col_names_wrong <- c("col1", "col2")
# Call the function with the mismatched column names vector
expect_error(initial_data(
"./tests/testthat/helpers/data/data_set.csv",
col_names_wrong
))
# Delete the helper file
file.remove("./tests/testthat/helpers/data/data_set.csv")
})
load_all()
?initial_data
test()
check()
load_all()
document()
document()
document()
?split_dataset
load_all()
document()
check()
use_test(split_dataset())
library(rsample)
use_test(split_dataset
\\]\
use_test(split_dataset)
use_test("split_dataset")
styler:::style_active_file()
load_all()
# Define the split_dataset function
split_dataset <- function(data_set, strata_variable, predictor) {
split <- initial_split(data_set, prop = 0.75, strata = strata_variable)
training_data <- training(split)
testing_data <- testing(split)
return(list(training_data, testing_data))
}
# Create a helper script to provide data for the tests
# Example data
set.seed(123)
data_set <- data.frame(
x = rnorm(100),
y = sample(c("A", "B", "C"), 100, replace = TRUE),
z = rnorm(100)
)
strata_variable <- "y"
predictor <- "x"
# Create expected training and testing datasets
split <- initial_split(data_set, prop = 0.75, strata = strata_variable)
expected_training_data <- training(split)
expected_testing_data <- testing(split)
load_all()
check()
library(rsample)
test()
test()
check()
document()
check()
check()
View(data_set)
load_all()
check()
test()
test_that("split_dataset function splits data set into training and testing
sets correctly", {
# Call the function
set.seed(123)
actual_split <- split_dataset(data_set, strata_variable, predictor)
# Test that the training set has the expected number of observations
expect_equal(nrow(actual_split[[1]]), nrow(expected_training_data))
# Test that the testing set has the expected number of observations
expect_equal(nrow(actual_split[[2]]), nrow(expected_testing_data))
# Test that the training set and testing set are mutually exclusive
expect_equal(intersect(
rownames(actual_split[[1]]),
rownames(actual_split[[2]])
), character(0))
})
# Define test cases
test_that("split_dataset function returns a list with two data frames", {
# Call the function
set.seed(123)
actual_split <- split_dataset(data_set, strata_variable, predictor)
# Test that the function returns a list with two data frames
expect_is(actual_split, "list")
expect_equal(length(actual_split), 2)
expect_is(actual_split[[1]], "data.frame")
expect_is(actual_split[[2]], "data.frame")
})
# Define test cases
test_that("split_dataset function returns a list with two data frames", {
# Call the function
set.seed(123)
data_set <- data.frame(
x = rnorm(100),
y = sample(c("A", "B", "C"), 100, replace = TRUE),
z = rnorm(100)
)
strata_variable <- "y"
predictor <- "x"
actual_split <- split_dataset(data_set, strata_variable, predictor)
# Test that the function returns a list with two data frames
expect_is(actual_split, "list")
expect_equal(length(actual_split), 2)
expect_is(actual_split[[1]], "data.frame")
expect_is(actual_split[[2]], "data.frame")
})
# Define test cases
test_that("split_dataset function returns a list with two data frames", {
# Call the function
set.seed(123)
data_set <- data.frame(
x = rnorm(100),
y = sample(c("A", "B", "C"), 100, replace = TRUE),
z = rnorm(100)
)
strata_variable <- "y"
predictor <- "x"
actual_split <- split_dataset(data_set, strata_variable, predictor)
# Test that the function returns a list with two data frames
expect_is(actual_split, "list")
expect_equal(length(actual_split), 2)
expect_is(actual_split[[1]], "data.frame")
expect_is(actual_split[[2]], "data.frame")
})
# Define test cases
test_that("split_dataset function returns a list with two data frames", {
# Call the function
set.seed(123)
data_set <- data.frame(
x = rnorm(100),
y = sample(c("A", "B", "C"), 100, replace = TRUE),
z = rnorm(100)
)
strata_variable <- "y"
predictor <- "x"
actual_split <- split_dataset(data_set, strata_variable, predictor)
# Test that the function returns a list with two data frames
expect_type(actual_split, "list")
expect_equal(length(actual_split), 2)
expect_type(actual_split[[1]], "data.frame")
expect_type(actual_split[[2]], "data.frame")
})
# Define test cases
test_that("split_dataset function returns a list with two data frames", {
# Call the function
set.seed(123)
data_set <- data.frame(
x = rnorm(100),
y = sample(c("A", "B", "C"), 100, replace = TRUE),
z = rnorm(100)
)
strata_variable <- "y"
predictor <- "x"
actual_split <- split_dataset(data_set, strata_variable, predictor)
# Test that the function returns a list with two data frames
expect_type(actual_split, "list")
expect_equal(length(actual_split), 2)
expect_type(actual_split[[1]], "list")
expect_type(actual_split[[2]], "lists")
})
# Define test cases
test_that("split_dataset function returns a list with two data frames", {
# Call the function
set.seed(123)
data_set <- data.frame(
x = rnorm(100),
y = sample(c("A", "B", "C"), 100, replace = TRUE),
z = rnorm(100)
)
strata_variable <- "y"
predictor <- "x"
actual_split <- split_dataset(data_set, strata_variable, predictor)
# Test that the function returns a list with two data frames
expect_type(actual_split, "list")
expect_equal(length(actual_split), 2)
expect_type(actual_split[[1]], "list")
expect_type(actual_split[[2]], "list")
})
test_that("split_dataset function splits data set into training and testing
sets correctly", {
# Call the function
set.seed(123)
actual_split <- split_dataset(data_set, strata_variable, predictor)
# Test that the training set has the expected number of observations
expect_equal(nrow(actual_split[[1]]), nrow(expected_training_data))
# Test that the testing set has the expected number of observations
expect_equal(nrow(actual_split[[2]]), nrow(expected_testing_data))
# Test that the training set and testing set are mutually exclusive
expect_equal(intersect(
rownames(actual_split[[1]]),
rownames(actual_split[[2]])
), character(0))
})
styler:::style_active_file()
# Define test cases
test_that("split_dataset function returns a list with two data frames", {
# Call the function
set.seed(123)
data_set <- data.frame(
x = rnorm(100),
y = sample(c("A", "B", "C"), 100, replace = TRUE),
z = rnorm(100)
)
strata_variable <- "y"
predictor <- "x"
actual_split <- split_dataset(data_set, strata_variable, predictor)
# Test that the function returns a list with two data frames
expect_type(actual_split, "list")
expect_equal(length(actual_split), 2)
expect_type(actual_split[[1]], "list")
expect_type(actual_split[[2]], "list")
})
test_that("split_dataset function splits data set into training and testing
sets correctly", {
# Create a helper script to provide data for the tests
# Example data
set.seed(123)
data_set <- data.frame(
x = rnorm(100),
y = sample(c("A", "B", "C"), 100, replace = TRUE),
z = rnorm(100)
)
strata_variable <- "y"
predictor <- "x"
# Create expected training and testing datasets
split <- initial_split(data_set, prop = 0.75, strata = strata_variable)
expected_training_data <- training(split)
expected_testing_data <- testing(split)
actual_split <- split_dataset(data_set, strata_variable, predictor)
# Test that the training set has the expected number of observations
expect_equal(nrow(actual_split[[1]]), nrow(expected_training_data))
# Test that the testing set has the expected number of observations
expect_equal(nrow(actual_split[[2]]), nrow(expected_testing_data))
# Test that the training set and testing set are mutually exclusive
expect_equal(intersect(
rownames(actual_split[[1]]),
rownames(actual_split[[2]])
), character(0))
})
test_that("split_dataset function splits data set into training and testing
sets correctly", {
# Create a helper script to provide data for the tests
# Example data
set.seed(123)
data_set <- data.frame(
x = rnorm(100),
y = sample(c("A", "B", "C"), 100, replace = TRUE),
z = rnorm(100)
)
strata_variable <- "y"
predictor <- "x"
# Create expected training and testing datasets
split <- initial_split(data_set, prop = 0.75, strata = strata_variable)
expected_training_data <- training(split)
expected_testing_data <- testing(split)
actual_split <- split_dataset(data_set, strata_variable, predictor)
# Test that the training set has the expected number of observations
expect_equal(nrow(actual_split[[1]]), nrow(expected_training_data))
# Test that the testing set has the expected number of observations
expect_equal(nrow(actual_split[[2]]), nrow(expected_testing_data))
# Test that the training set and testing set are mutually exclusive
expect_equal(intersect(
rownames(actual_split[[1]]),
rownames(actual_split[[2]])
), character(0))
})
test_that("split_dataset function splits data set into training and testing
sets with correct proportion", {
# Call the function
set.seed(123)
data_set <- data.frame(
x = rnorm(100),
y = sample(c("A", "B", "C"), 100, replace = TRUE),
z = rnorm(100)
)
strata_variable <- "y"
predictor <- "x"
actual_split <- split_dataset(data_set, strata_variable, predictor)
# Test that the proportion of observations in the training set is correct
expect_equal(nrow(actual_split[[1]]) / nrow(data_set), 0.75, tolerance = 0.02)
# Test that the proportion of observations in the testing set is correct
expect_equal(nrow(actual_split[[2]]) / nrow(data_set), 0.26, tolerance = 0.02)
})
test()
test()
# Define test cases
test_that("split_dataset function returns a list with two data frames", {
# Call the function
set.seed(123)
data_set <- data.frame(
x = rnorm(100),
y = sample(c("A", "B", "C"), 100, replace = TRUE),
z = rnorm(100)
)
strata_variable <- "y"
predictor <- "x"
actual_split <- split_dataset(data_set, all_of(strata_variable), all_of(predictor))
# Test that the function returns a list with two data frames
expect_type(actual_split, "list")
expect_equal(length(actual_split), 2)
expect_type(actual_split[[1]], "list")
expect_type(actual_split[[2]], "list")
})
test_that("split_dataset function splits data set into training and testing
sets correctly", {
# Create a helper script to provide data for the tests
# Example data
set.seed(123)
data_set <- data.frame(
x = rnorm(100),
y = sample(c("A", "B", "C"), 100, replace = TRUE),
z = rnorm(100)
)
strata_variable <- "y"
predictor <- "x"
# Create expected training and testing datasets
split <- initial_split(data_set, prop = 0.75, strata = all_of(strata_variable))
expected_training_data <- training(split)
expected_testing_data <- testing(split)
actual_split <- split_dataset(data_set, all_of(strata_variable), all_of(predictor))
# Test that the training set has the expected number of observations
expect_equal(nrow(actual_split[[1]]), nrow(expected_training_data))
# Test that the testing set has the expected number of observations
expect_equal(nrow(actual_split[[2]]), nrow(expected_testing_data))
# Test that the training set and testing set are mutually exclusive
expect_equal(intersect(
rownames(actual_split[[1]]),
rownames(actual_split[[2]])
), character(0))
})
test_that("split_dataset function splits data set into training and testing
sets with correct proportion", {
# Call the function
set.seed(123)
data_set <- data.frame(
x = rnorm(100),
y = sample(c("A", "B", "C"), 100, replace = TRUE),
z = rnorm(100)
)
strata_variable <- "y"
predictor <- "x"
actual_split <- split_dataset(data_set, all_of(strata_variable), all_of(predictor))
# Test that the proportion of observations in the training set is correct
expect_equal(nrow(actual_split[[1]]) / nrow(data_set), 0.75, tolerance = 0.02)
# Test that the proportion of observations in the testing set is correct
expect_equal(nrow(actual_split[[2]]) / nrow(data_set), 0.26, tolerance = 0.02)
})
test()
check()
load_all()
check()
test()
check()
check()
check()
check()
load_all()
document()
?accuracy_plot
check()
check()
check()
check()
?scatterplot
?horizontal_hist
check()
check()
styler:::style_active_file()
accuracy_plot <- function(workflow_data, x_label, y_label, plot_title) {
options(repr.plot.width = 12, repr.plot.width = 12)
accuracy <- filter(workflow_data, .metric == "accuracy")
acc_plot <- ggplot(accuracy, aes(x = neighbors, y = mean)) +
geom_point() +
geom_line() +
labs(x = x_label, y = y_label, title = plot_title) +
theme(text = element_text(size = 20)) +
scale_x_continuous(breaks = c(1:30))
return(acc_plot)
}
load_all()
check()
load_all()
check()
check()
