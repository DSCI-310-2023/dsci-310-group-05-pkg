---
title: "Introduction to group05pkg"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{group05pkg-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  comment = "#>",
  warning = FALSE,
  message = FALSE
)
```

```{r load_all, include=FALSE}
devtools::load_all(".")
```

Data analysis requires a structured approach that involves cleaning, wrangling,
modeling, and evaluating the performance of different models. However, these 
tasks can be challenging, and traditional approaches of writing large code chunks
to run this kind of analysis can be time-consuming and error-prone.

**This is where the package group05pkg comes in!**

It provides a set of easy-to-use functions that simplify the process of running
a classification analysis such as:

- Split your data set into train and test
- Create the components of a classification model such as the KNN specification,
a recipe, cross-validation folds, and a grid of hyperparameters that can be used
to tune the performance of a model.
- Evaluate the accuracy of your model. 
- Plot histograms and scatterplots to visualize your analysis. 

This document introduces you to group05pkgâ€™s basic set of tools, and shows you 
how to apply them to run a classification analysis.

## Data: drug_consumption
To explore the package, we will be using the `drug_consumption` data set. This data
set has `1884 rows` and `32 columns`.

```{r setup, include = FALSE}
library(group05pkg)
library(dplyr)
library(stringr)
library(forcats)
```

```{r drug-consumption}
url <-"https://archive.ics.uci.edu/ml/machine-learning-databases/00373/drug_consumption.data"
drug_consumption <- readr::read_csv(url)

colnames(drug_consumption) <- c(
  "ID", "Age", "Gender", "Education", "Country", "Ethnicity",
  "Nscore", "Escore", "Oscore", "Ascore", "Cscore",
  "Impulsive", "SS", "Alcohol", "Amphet", "Amyl", "Benzos",
  "Caff", "Cannabis", "Choc", "Coke", "Crack", "Ecstasy",
  "Heroin", "Ketamine", "Legalh", "LSD", "Meth", "Mushrooms",
  "Nicotine", "Semer", "VSA"
)
head(drug_consumption)
```

```{r data-cleaning-1, include = FALSE}
drug_consumption <- select(
  drug_consumption, Age, Gender, Nscore, Escore, Oscore, Ascore, Nicotine,
  Cannabis
) %>%
  mutate(Cannabis = str_replace_all(
    Cannabis,
    c(
      "CL0" = "no",
      "CL1" = "no",
      "CL2" = "no",
      "CL3" = "yes",
      "CL4" = "yes",
      "CL5" = "yes",
      "CL6" = "yes"
    )
  )) %>%
  mutate(Cannabis = as_factor(Cannabis)) %>%
  mutate(Nicotine = str_replace_all(
    Nicotine,
    c(
      "CL0" = "no",
      "CL1" = "no",
      "CL2" = "no",
      "CL3" = "yes",
      "CL4" = "yes",
      "CL5" = "yes",
      "CL6" = "yes"
    )
  ))
```
## Functions

We can break down our functions into 3 different groups: 

- EDA 
- Visualizations
- Classification Models

### EDA

#### 1. Split the dataset into training and testing sets 

The `split_dataset` is a function that splits a dataset into training and test 
sets. The function takes in a dataset, a strata variable, and a predictor variable
as inputs and performs a stratified random split of the dataset into training and
testing subsets.

`data_set` argument is a data frame containing the original data that will be 
split into training and testing sets. `strata_variable` is a string specifying 
the variable in `data_set` that will be used as a stratification variable for 
the split. `predictor` is a string that indicates the variable in the `data_set`
that is going to be considered as the predictor variable.

The function returns a list that contains the training set and testing set. 

For example, we can use `split_dataset()` function by providing 
`data_set = drug_consumption`, `strata_dariable = "Canabis"` and `predictor = "Nicotine"`.
This will split our `drug_consumption` into train and test sets.

```{r split_dataset}
split_data <- split_dataset(drug_consumption, "Cannabis", "Nicotine")
train_data <- split_data[[1]]
test_data<- split_data[[2]]
```

```{r data-cleaning-2, include=FALSE}
test_data <- mutate(test_data,
  Nicotine = str_replace_all(
    Nicotine,
    c(
      "no" = "0",
      "yes" = "1"
    )
  )
) %>%
  mutate(Nicotine = as.numeric(Nicotine))
```

#### 2. Clean and wrangle data

The `wrangle_training_data` function takes in a training dataset, a predictor 
variable, a strata variable, and group labels as inputs, and returns a data frame
with 4 columns that are named as "predictor", "strata_variable", "n", and "label". 

The function groups the training data by the predictor and strata variable, 
summarizes the number of observations in each group, and lastly  adds a label 
column with group labels that are defined by the user.

`training_data` argument is a data frame that contains the training data that is
going to be wrangled and cleaned. `predictor` argument is a string or that spcifies
the variable in the training data that is gonna be used as the predictor variable.
`strata_variable` is a string that specifies the variable in the training data to
be used as the stratification variable.`group_labels` is a strings to be used as 
labels for the groups in the resulting data frame.

For example we can use `wrangle_training_data` function by providing `training_data = train_data`,
`strata_dariable = "Canabis"` and `predictor = "Nicotine"` and `group_labels = labels` where `lables`
is defined as  `c("Neither", "Cannabis only", "Nicotine only", "Both")`. 

As a result, the function will return  a data frame with four columns: predictor, strata_variable, n, label.

```{r wrangle_training_data}

labels <- c("Neither", "Cannabis only", "Nicotine only", "Both")
cannabis_and_nicotine <- wrangle_training_data(
  train_data,
  Nicotine, 
  Cannabis,
  labels
)

```

### Visualizations

#### 1. Build a horizontal histogram with `horizontal_hist()`




#### 2. Build a scatter plot with `scatterplot()`


#### 3. Build a plot to help understand the accuracies with `accuracy_plot()`

### Classification Models 

#### 1. Create knn specification with `create_knn_spec()`

`create_knn_spec()` is a function that creates a specification object for k-nearest
neighbor (KNN) models. The function takes one argument, weight_func, which is a 
string that specifies the weight function to use in the model.


The function creates a specification object using the `nearest_neighbor()` function
from the `parsnip` package. The weight_func argument is used to set the weight 
function in the specification object.

The neighbors parameter is set as a tuning parameter using the `tune()` function. 
This means that the number of neighbors will be selected based on the best 
performance during model training.

The specification object is then set to use the kknn engine and set to 
classification mode. Finally, the function returns the specification object.

To use the `create_knn_spec()` function, you simply provide a string for the 
weight_func argument. For example, to create a specification object with a weight 
function of "rectangular", you can use the following code:

```{r create-knn-spec}
drugs_knn_spec <- create_knn_spec("rectangular")
drugs_knn_spec
```
#### 2. Create knn specification with `create_recipe()`

`create_recipe()` is a function that creates a recipe object for use in a modeling
workflow. The function takes two arguments: data, a dataframe containing the data,
and response_var, a string that specifies the name of the response variable.

The function creates a recipe object using the `recipe()` function from the `recipes`
package. The `as.formula()` function is used to create a formula where the response
variable is specified as the response_var argument, and all other columns in the
input dataframe are used as predictors.

The recipe object includes two steps: scaling and centering the predictor variables.
These steps are added to the recipe object using the `step_scale()` and `step_center()`
functions from the `recipes` package. Finally, the function returns the recipe object,
which can be used in a modeling workflow.

To use the `create_recipe()` function, you need to provide a dataframe for the data
argument and a string for the response_var argument. For example, to create a recipe
object for the drug_consumption dataframe with the response variable set to "Cannabis",
you can use the following code:

```{r create-recipe}
drugs_recipe <- create_recipe(data = train_data, response_var = "Cannabis")
drugs_recipe
```
#### 3. Create vfold with `create_vfold()`

`create_vfold()` is a function that creates a v-fold cross-validation object for 
use in a modeling workflow. The function takes three arguments: data, which is a
dataframe containing the data, v, which is an integer specifying the number of 
folds, and strata, which specifies  the name of the strata variable for stratified sampling.

The function creates a v-fold cross-validation object using the `vfold_cv()` function
from the `rsample` package. The data and v arguments are passed to `vfold_cv()`, and
the strata argument is used for stratified sampling if provided. The function then
returns the v-fold cross-validation object.

For example, if you wanted to create a v-fold cross-validation object with 5 folds
and stratified by the "Cannabis" variable, you can use the following code:

```{r create-vfold}
drugs_vfold <- create_vfold(train_data, 5, "Cannabis")
drugs_vfold
```

#### 4. Create grid with `create_grid()`

`create_grid()` is a function that generates a grid of values to tune over for 
the number of nearest neighbors in the k-nearest neighbor classification model. 
It takes two arguments: min_neighbors, which is an integer specifying the minimum
number of neighbors to include in the grid, and max_neighbors, which is an integer
specifying the maximum number of neighbors to include in the grid.

The function then creates a tibble containing a sequence of integers ranging from
the specified min_neighbors to max_neighbors, inclusive. The tibble contains a 
single column named "neighbors" which represents the number of neighbors to use 
in the k-nearest neighbor model. Finally, the function returns the tibble.

For example, if you wanted to generate a grid of values to tune over for the number
of nearest neighbors in the k-nearest neighbor classification model, where the 
minimum number of neighbors is 1 and the maximum number of neighbors is 30, 
you can use the following code:

```{r create-grid}
drugs_grid <- create_grid(1, 30)
drugs_grid
```

#### 5. Predict Accuracy of Workflow with `predict_drugs_workflow`

`predict_drugs_workflow()` is a function that predicts the outcome of a target 
variable for new test data given a fitted KNN workflow object.The function takes
two arguments: knn_wf, which is a fitted KNN workflow object, and test_data, which
is a data frame containing new test data to predict the outcome of cannabis usage.

The function uses the `predict()` function from the `stats` package to predict the 
outcome of the strata variable on new test data using the KNN model in knn_wf. 
The predicted outcome is then combined with the original test data using the 
`bind_cols()` function from the `dplyr` package to create a new data frame 
containing the predicted outcome.

Finally, the function returns the new data frame containing the predicted outcome
of the strata variable for the new test data. Additionally, the predicted outcome
is written to the data folder.

For example, if you had a fitted KNN workflow object called drugs_workflow and a
data frame of new test data called test_data, you could use the following code to
predict the outcome of cannabis usage for the new test data and write the predicted
outcome to the data folder:

```{r predict_drugs_workflow}
drugs_real_spec <- nearest_neighbor(
  weight_func = "rectangular",
  neighbors = 23
) %>%
  set_engine("kknn") %>%
  set_mode("classification")

drugs_real_workflow <- workflow() %>%
  add_recipe(drugs_recipe) %>%
  add_model(drugs_real_spec) %>%
  fit(data = test_data)

# calculating how well the training data predicts the testing data
drugs_pred <- predict_drugs_workflow(drugs_real_workflow, test_data)
drugs_pred
```
